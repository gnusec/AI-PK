#!/usr/bin/env python3
"""
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• 
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â•â•šâ•â•      â•šâ•â•     â•šâ•â•  â•šâ•â•    â•šâ•â•     â•šâ•â•  â•šâ•â•
                                                       
Cyberpunk AI Benchmark Analyzer - ZigScan Edition
Author: @gnusec | Target: AI Engine Performance Analysis
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
from collections import defaultdict

BENCH_PATH = "/home/winger/code/zig/ai-pk/benchmarks/zigscan"

# å¼•æ“å’Œå®¢æˆ·ç«¯æ˜ å°„
ENGINE_PATTERNS = {
    'gpt5': 'GPT-5',
    'gpt4': 'GPT-4',
    'claude': 'Claude',
    'sonnet': 'Claude Sonnet',
    'opus': 'Claude Opus',
    'glm4': 'GLM-4',
    'qwen': 'Qwen',
    'grok': 'Grok',
    'supernova': 'Supernova',
    'kat': 'Kat',
    'kimi': 'Kimi',
}

CLIENT_PATTERNS = {
    'droid': 'Droid',
    'dorid': 'Droid',  # typo in naming
    'cline': 'Cline',
    'kilo': 'Kilo', 
    'roo': 'Roo',
    'codex': 'Codex',
    'claudecode': 'ClaudeCode',
    'cli': 'CLI',
}

def parse_engine_client(dirname: str) -> tuple:
    """ä»ç›®å½•åæå–å¼•æ“å’Œå®¢æˆ·ç«¯ - ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ˜¯å¼•æ“ï¼Œå…¶ä½™éƒ½æ˜¯å®¢æˆ·ç«¯/é…ç½®"""
    dirname_lower = dirname.lower()
    
    # æ”¯æŒä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦åˆ†å‰²
    # æ ¼å¼1: engine-client-config (å¦‚ gpt5-codex-low)
    # æ ¼å¼2: engine_config-client (å¦‚ gpt5_codex_medium-codex)
    # å…ˆæŒ‰ '-' åˆ†å‰²ä¸»è¦éƒ¨åˆ†
    if '-' in dirname:
        main_parts = dirname.split('-', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªè¿å­—ç¬¦
        engine_part = main_parts[0]
        client_part = main_parts[1] if len(main_parts) > 1 else ""
        
        # å¦‚æœengine_partåŒ…å«ä¸‹åˆ’çº¿ï¼Œè¯´æ˜æ˜¯ engine_config æ ¼å¼
        if '_' in engine_part:
            # gpt5_codex_medium-codex -> engine=gpt5_codex_medium, client=codex
            parts = [engine_part, client_part] if client_part else [engine_part]
        else:
            # gpt5-codex-low -> æ­£å¸¸åˆ†å‰²
            parts = dirname.split('-')
    else:
        # æ²¡æœ‰è¿å­—ç¬¦ï¼Œå°è¯•ä¸‹åˆ’çº¿
        parts = dirname.split('_') if '_' in dirname else [dirname]
    
    engine = "Unknown"
    client_parts = []
    
    # ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ˜¯å¼•æ“ï¼ˆå¯èƒ½åŒ…å«ä¸‹åˆ’çº¿çš„é…ç½®ï¼‰
    if len(parts) > 0:
        first = parts[0].lower()
        # å¤„ç† gpt5_codex_medium è¿™ç§æ ¼å¼
        if '_' in first:
            # æå–å¼•æ“åå’Œé…ç½®
            sub_parts = first.split('_')
            if 'gpt5' in sub_parts[0] or 'gpt4' in sub_parts[0]:
                engine = "GPT-5" if 'gpt5' in sub_parts[0] else "GPT-4"
                # æŠŠé…ç½®éƒ¨åˆ†ä¹ŸåŠ å…¥å¼•æ“å
                if len(sub_parts) > 1:
                    config = '_'.join(sub_parts[1:])
                    engine = f"{engine} ({config})"
            elif 'glm' in sub_parts[0]:
                engine = "GLM-4"
                if len(sub_parts) > 1:
                    engine = f"{engine} ({sub_parts[1]})"
            else:
                engine = first.replace('_', ' ').title()
        else:
            # æ™®é€šæ ¼å¼
            if 'gpt5' in first or 'gpt4' in first:
                engine = "GPT-5" if 'gpt5' in first else "GPT-4"
            elif 'claude' in first:
                engine = "Claude"
            elif 'sonnet' in first:
                engine = "Claude Sonnet"
            elif 'opus' in first:
                engine = "Claude Opus"
            elif 'glm' in first:
                engine = "GLM-4"
            elif 'qwen' in first:
                engine = "Qwen"
            elif 'grok' in first:
                engine = "Grok"
            elif 'supernova' in first:
                engine = "Supernova"
            elif 'kat' in first:
                engine = "Kat"
            elif 'kimi' in first:
                engine = "Kimi"
            else:
                engine = parts[0].capitalize()
    
    # å…¶ä½™éƒ¨åˆ†ç»„æˆå®¢æˆ·ç«¯/é…ç½®æè¿°
    if len(parts) > 1:
        # é™¤äº†ç¬¬ä¸€ä¸ªå¼•æ“éƒ¨åˆ†ï¼Œå…¶ä»–éƒ½æ˜¯å®¢æˆ·ç«¯/é…ç½®
        client_parts = parts[1:]
        client = '-'.join([p.capitalize() for p in client_parts])
        # å»é™¤æ—¥æœŸåç¼€ï¼ˆå¦‚ -2025-10-25ï¼‰
        import re
        client = re.sub(r'-\d{4}-\d{2}-\d{2}$', '', client)
    else:
        client = "Default"
    
    return engine, client

def extract_user_comments(content: str) -> List[str]:
    """æå–finish.logä¸­çš„ç”¨æˆ·è¯„è®ºå’Œå…³é”®æè¿°"""
    comments = []
    
    # å¯»æ‰¾åˆ†éš”çº¿ä¹‹é—´çš„å†…å®¹
    sections = re.split(r'-{5,}', content)
    for section in sections:
        section = section.strip()
        if not section:
            continue
        
        # è¿‡æ»¤æ‰çº¯ç²¹çš„æ—¶é—´æˆ³ã€å‘½ä»¤è¾“å‡º
        if re.match(r'^\d{4}å¹´', section):
            continue
        if section.startswith('$'):
            continue
        if 'real' in section and 'user' in section and 'sys' in section:
            continue
        
        # æå–æœ‰æ„ä¹‰çš„è¯„è®º
        lines = [l.strip() for l in section.split('\n') if l.strip()]
        for line in lines:
            if len(line) < 10:  # å¤ªçŸ­çš„å¿½ç•¥
                continue
            if any(keyword in line for keyword in ['å¯ç”¨', 'å®Œæˆ', 'å¤±è´¥', 'æ‰¯æ·¡', 'æ€»ç»“', 'è¯„ä»·', 'ç»“è®º', 'bug', 'Bug', 'token']):
                comments.append(line)
    
    return comments[:5]  # æœ€å¤š5æ¡

def parse_finish_log_fallback(log_path: str) -> Dict:
    """æ·±åº¦è§£æfinish.log"""
    result = {
        "test_dir": os.path.basename(os.path.dirname(log_path)),
        "engine": "Unknown",
        "client": "Unknown",
        "completed": "unknown",
        "time_minutes": None,
        "tokens": None,
        "notes": "",
        "user_comments": [],
        "quality_score": 0,  # è´¨é‡è¯„åˆ† 0-10
    }
    
    # è§£æå¼•æ“å’Œå®¢æˆ·ç«¯
    result["engine"], result["client"] = parse_engine_client(result["test_dir"])
    
    try:
        with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        # æå–æ—¶é—´
        time_match = re.search(r'real\s+(\d+)m([\d.]+)s', content)
        if time_match:
            result["time_minutes"] = int(time_match.group(1)) + float(time_match.group(2))/60
        
        time_match2 = re.search(r'ç”¨æ—¶[ï¼š:]*\s*(\d+)\s*åˆ†é’Ÿ', content)
        if time_match2:
            result["time_minutes"] = int(time_match2.group(1))
        
        # æ—¶é—´è®¡ç®—ï¼ˆå¼€å§‹-ç»“æŸï¼‰
        if 'ç”¨æ—¶' in content or 'Wall Time' in content:
            time_context = re.search(r'(\d+)h\s*(\d+)m\s*(\d+)s', content)
            if time_context:
                h, m, s = map(int, time_context.groups())
                result["time_minutes"] = h * 60 + m + s / 60
        
        # æå–tokens - å¤šç§æ ¼å¼
        token_patterns = [
            r'tokens?\s*(?:used|Usage|æ¶ˆè€—)[ï¼š:]*\s*([\d,_]+)',
            r'Input.*?:\s*([\d,_]+)',
            r'Output.*?:\s*([\d,_]+)',
        ]
        for pattern in token_patterns:
            token_match = re.search(pattern, content, re.IGNORECASE)
            if token_match:
                result["tokens"] = int(token_match.group(1).replace(',', '').replace('_', ''))
                break
        
        # åˆ¤æ–­å®Œæˆæƒ…å†µ - åŸºäºæ‰‹å†™finish.logçš„ä¸¥æ ¼åˆ¤æ–­
        content_lower = content.lower()
        
        # 1. æ˜ç¡®å¤±è´¥çš„å…³é”®è¯ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        fail_keywords = ['æ— æ³•å®Œæˆ', 'æ— æ³•æˆåŠŸ', 'ä¸å†æµ‹è¯•', 'å¤±è´¥', 'å¾ˆæ‰¯æ·¡', 'åŸºæœ¬ä¸å¯ç”¨']
        if any(word in content for word in fail_keywords):
            result["completed"] = "âŒ FAILED"
            result["quality_score"] = 0
            if 'æ— æ³•å®Œæˆ' in content or 'æ— æ³•æˆåŠŸ' in content:
                result["notes"] = "Cannot complete"
            elif 'å¾ˆæ‰¯æ·¡' in content:
                result["notes"] = "Total garbage"
            elif 'åŸºæœ¬ä¸å¯ç”¨' in content:
                result["notes"] = "Not working"
        
        # 2. æ˜ç¡®æˆåŠŸçš„å…³é”®è¯ï¼ˆåŸºäºæ‰‹å†™è¯„ä»·ï¼‰
        elif any(word in content for word in [
            'æ•´ä½“å¯ç”¨', 
            'åŠŸèƒ½å®Œå…¨å¯ç”¨', 
            'å®Œæˆåº¦å¾ˆé«˜', 
            'ä»»åŠ¡å®Œæˆï¼ŒåŠŸèƒ½æ­£å¸¸',
            'åŠŸèƒ½æ­£å¸¸',
            'éå¸¸æµç¨‹'
        ]) and 'zig-out/bin' in content:
            result["completed"] = "âœ… SUCCESS"
            result["quality_score"] = 8
            if 'æ²¡é—®é¢˜' in content or 'å®Œæˆåº¦å¾ˆé«˜' in content:
                result["notes"] = "Fully working"
        
        # 3. éƒ¨åˆ†å¯ç”¨ï¼ˆæœ‰è¿è¡Œè¾“å‡ºä½†æœ‰é—®é¢˜ï¼‰
        elif 'å¤§éƒ¨åˆ†å¯ç”¨' in content:
            result["completed"] = "âš ï¸ PARTIAL"
            result["quality_score"] = 5
            if 'å¹¶å‘æ§åˆ¶' in content and 'æ— æ•ˆ' in content:
                result["notes"] = "Concurrency broken"
            else:
                result["notes"] = "Mostly working"
        
        # 4. æ€»ä½“å¯ç”¨ä½†æœ‰æŠ•æœºè¡Œä¸ºæˆ–å…¶ä»–é—®é¢˜
        elif 'æ€»ä½“å¯ç”¨' in content:
            result["completed"] = "âš ï¸ PARTIAL"
            result["quality_score"] = 6
            if 'ncat' in content or 'æŠ•æœº' in content:
                result["notes"] = "Uses workarounds"
            else:
                result["notes"] = "Generally working"
        
        # 5. å¯ç”¨ä½†æœ‰ä¸¥é‡bugï¼ˆinteger overflowç­‰ï¼‰
        elif ('å¯ä»¥ç”¨' in content or 'å¯ç”¨' in content) and ('integer overflow' in content or 'panic' in content):
            result["completed"] = "âš ï¸ PARTIAL"
            result["quality_score"] = 4
            result["notes"] = "Has critical bugs"
        
        # 6. æœ‰è¿è¡Œè¾“å‡ºä¸”å¯ç”¨
        elif 'zig-out/bin' in content and any(word in content for word in ['Scan completed', 'Open ports', 'å¯ä»¥ç”¨']):
            result["completed"] = "âœ… SUCCESS"
            result["quality_score"] = 7
        
        # 7. é»˜è®¤ä¸æ˜ç¡®
        else:
            result["completed"] = "â“ UNCLEAR"
            result["quality_score"] = 3
        
        # æå–ç”¨æˆ·è¯„è®º
        result["user_comments"] = extract_user_comments(content)
        
        # æå–å…³é”®æè¿°ä½œä¸ºnotes
        if 'bug' in content_lower or 'Bug' in content:
            result["notes"] = "Has bugs"
            result["quality_score"] = max(result["quality_score"] - 2, 0)
        elif 'åŠŸèƒ½æ­£å¸¸' in content:
            result["notes"] = "Fully working"
        elif 'å¤§éƒ¨åˆ†å¯ç”¨' in content:
            result["notes"] = "Mostly working"
        elif 'ä¸å¯ç”¨' in content or 'åŸºæœ¬ä¸å¯ç”¨' in content:
            result["notes"] = "Not working"
            result["quality_score"] = 1
        elif 'æ‰¯æ·¡' in content:
            result["notes"] = "Total failure"
            result["quality_score"] = 0
            
    except Exception as e:
        print(f"âš ï¸  Warning: Error parsing {log_path}: {e}")
    

def load_stats_json(test_dir):
    """ä»stats.jsonåŠ è½½æµ‹è¯•æ•°æ®ï¼ˆä¼˜å…ˆï¼‰"""
    stats_file = os.path.join(test_dir, 'stats.json')
    if not os.path.exists(stats_file):
        return None
    
    try:
        with open(stats_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
        return {
            'test_dir': data.get('test_dir', os.path.basename(test_dir)),
            'engine': data.get('engine', 'Unknown'),
            'client': data.get('client', 'Unknown'),
            'config': data.get('config', ''),
            'completed': data.get('completed', 'UNCLEAR'),
            'time_minutes': data.get('time_minutes'),
            'tokens': data.get('tokens'),
            'quality_score': data.get('quality_score', 0),
            'notes': data.get('notes', ''),
            'user_comments': [data.get('detailed_comments', '')],
            'issues': data.get('issues', []),
            'metadata': data.get('metadata', {}),
            'source': 'stats.json'
        }
    except Exception as e:
        print(f"[!] Error loading stats.json from {test_dir}: {e}")
        return None

    return result

def collect_all_results() -> List[Dict]:
    """æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ - ä¼˜å…ˆè¯»å–stats.json"""
    results = []
    
    # åªæ‰«æbenchmarks/zigscan/çš„ç›´æ¥å­ç›®å½•
    for item in os.listdir(BENCH_PATH):
        item_path = os.path.join(BENCH_PATH, item)
        if not os.path.isdir(item_path):
            continue
        
        # è·³è¿‡ç‰¹æ®Šç›®å½•
        if item in ['start-org', 'start-org-cline', '.marscode']:
            continue
        
        # ä¼˜å…ˆå°è¯•åŠ è½½stats.json
        stats_data = load_stats_json(item_path)
        if stats_data:
            print(f"[+] Loaded stats.json for {item}")
            results.append(stats_data)
            continue
        
        # å›é€€åˆ°è§£æfinish.log
        log_path = os.path.join(item_path, 'finish.log')
        if os.path.exists(log_path):
            result = parse_finish_log_fallback(log_path)
            results.append(result)
    
    # æ’åºï¼šæˆåŠŸçš„ä¼˜å…ˆï¼Œç„¶åæŒ‰æ—¶é—´
    return sorted(results, key=lambda x: (
        0 if 'âœ…' in x["completed"] else 1 if 'âš ï¸' in x["completed"] else 2 if 'â“' in x["completed"] else 3,
        x["time_minutes"] if x["time_minutes"] else 999999
    ))

def generate_ascii_art_header():
    """ç”Ÿæˆèµ›åšæœ‹å…‹é£æ ¼çš„header"""
    return """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—  â•‘
â•‘  â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•  â•‘
â•‘  â–ˆâ–ˆâ•‘      â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â•‘
â•‘  â–ˆâ–ˆâ•‘       â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•—   â•‘
â•‘  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—  â•‘
â•‘   â•šâ•â•â•â•â•â•   â•šâ•â•   â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â• â•šâ•â•  â•šâ•â•  â•‘
â•‘                                                                           â•‘
â•‘              â–‘â–’â–“ AI DEVELOPMENT BENCHMARK SYSTEM v1.0 â–“â–’â–‘               â•‘
â•‘                   ZigScan Security Tool Evaluation                       â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[*] SYSTEM: AI-PK Performance Analysis Framework
[*] TARGET: ZigScan Port Scanner Development
[*] METHOD: Real-world Project Benchmarking
[*] AUTHOR: @gnusec / Cybersecurity Research
â•‘  AI ENGINES TESTED                                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
"""
    
    for engine, count in sorted(engines.items(), key=lambda x: -x[1])[:8]:
        output += f"â•‘  {engine:20s} : {count:2d} tests                            â•‘\n"
    
    output += """â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    return output

def generate_leaderboard_ascii(results: List[Dict]) -> str:
    """ç”ŸæˆASCIIè‰ºæœ¯é£æ ¼çš„æ’è¡Œæ¦œ"""
    output = """
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                            ğŸ† LEADERBOARD ğŸ†                                  â”ƒ
â”ƒ              Top Performance: Speed Ã— Efficiency Ã— Quality                   â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›

â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ # â”‚ Engine + Client         â”‚ Status â”‚ Time(min)â”‚ Tokens   â”‚ Quality  â”ƒ
â”£â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”«
"""
    
    rank = 1
    for r in results[:20]:  # Top 20
        engine_client = f"{r['engine']} + {r['client']}"[:23]
        time_str = f"{r['time_minutes']:.1f}" if r['time_minutes'] else "N/A"
        token_str = f"{r['tokens']//1000}K" if r['tokens'] else "N/A"
        quality_bar = "â–ˆ" * r['quality_score'] + "â–‘" * (10 - r['quality_score'])
        
        output += f"â”ƒ{rank:3d}â”‚ {engine_client:23s} â”‚ {r['completed']:6s} â”‚{time_str:>9s} â”‚{token_str:>9s} â”‚ {quality_bar} â”ƒ\n"
        rank += 1
    
    output += """â”—â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”›

Legend:
  âœ… SUCCESS = Fully working    âš ï¸  = Partial/Mostly    âŒ = Failed    â“ = Unclear
  Quality Bar = â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (10/10 best)
"""
    return output

def generate_detailed_report(results: List[Dict]) -> str:
    """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
    output = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    DETAILED TEST RESULTS                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
    
    for i, r in enumerate(results, 1):
        output += f"""
â”Œâ”€ Test #{i:02d} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Directory   : {r['test_dir']:47s} â”‚
â”‚ AI Engine   : {r['engine']:47s} â”‚
â”‚ Client      : {r['client']:47s} â”‚
â”‚ Status      : {r['completed']:47s} â”‚
â”‚ Time        : {(str(r['time_minutes']) + ' min' if r['time_minutes'] else 'N/A'):47s} â”‚
â”‚ Tokens      : {(str(r['tokens']) if r['tokens'] else 'N/A'):47s} â”‚
â”‚ Quality     : {'â–“' * r['quality_score'] + 'â–‘' * (10-r['quality_score']):47s} â”‚
â”‚ Notes       : {r['notes']:47s} â”‚
"""
        if r['user_comments']:
            output += "â”‚ Comments    :                                               â”‚\n"
            for comment in r['user_comments'][:3]:
                comment_short = comment[:55]
                output += f"â”‚   â€¢ {comment_short:53s} â”‚\n"
        
        output += "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
    
    return output

def save_report(content: str, filename: str):
    """ä¿å­˜æŠ¥å‘Š"""
    output_path = f"/home/winger/code/zig/ai-pk/results/{filename}"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"[+] Report saved: {output_path}")

def main():
    print(generate_ascii_art_header())
    print("[*] Scanning benchmarks directory...")
    
    results = collect_all_results()
    print(f"[+] Found {len(results)} test results")
    
    # ç”Ÿæˆèµ›åšæœ‹å…‹é£æ ¼æŠ¥å‘Š
    report = ""
    report += generate_ascii_art_header()
    report += generate_stats_summary(results)
    report += generate_leaderboard_ascii(results)
    report += generate_detailed_report(results)
    
    # ä¿å­˜æŠ¥å‘Š
    save_report(report, "CYBERPUNK_REPORT.txt")
    
    # ä¹Ÿä¿å­˜JSONä¾›åç»­å¤„ç†
    json_data = json.dumps(results, indent=2, ensure_ascii=False)
    save_report(json_data, "benchmark_data.json")
    
    # æ‰“å°æ‘˜è¦åˆ°ç»ˆç«¯
    print(generate_stats_summary(results))
    print(generate_leaderboard_ascii(results)[:1000])
    
    print("\n[+] Analysis complete!")
    print("[+] Full report: results/CYBERPUNK_REPORT.txt")
    print("[+] JSON data: results/benchmark_data.json")

if __name__ == "__main__":
    main()
